{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "UnZip Files from a location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Nov17.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b66bd5663f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#dir_name = \"hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.chdir(dir_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Nov17.zip'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create zipfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/Lavanya/nov_unzipped'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# extract file to dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#zip_ref.close() # close file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/ANACONDA/Anaconda2.7/lib/python2.7/zipfile.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0mmodeDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'r'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'r+b'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Nov17.zip'"
     ]
    }
   ],
   "source": [
    "import os,zipfile\n",
    "#dir_name = \"hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/\"\n",
    "#os.chdir(dir_name)\n",
    "zip_ref = zipfile.ZipFile('hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Nov17.zip') # create zipfile object\n",
    "zip_ref.extractall('hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/Lavanya/nov_unzipped') # extract file to dir\n",
    "        #zip_ref.close() # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,zipfile\n",
    "dir_name = \"hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mLDA_Visualization.ipynb\u001b[0m*         \u001b[01;32mText Mining.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mNMF Modeling.ipynb\u001b[0m*              \u001b[01;32mText_PreProcessing.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mRead_Data_01.ipynb\u001b[0m*              \u001b[01;32mText_PreProcessing-V02.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mSpeech_Topics using LDA_2.html\u001b[0m*  \u001b[01;32mUntitled1.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mSpeech_Topics using LDA.html\u001b[0m*    \u001b[01;32mUntitled.ipynb\u001b[0m*\r\n",
      "\u001b[00mTest.html\u001b[0m                        \u001b[01;32mVerification.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mText Analysis.ipynb\u001b[0m*             \u001b[01;32mVisualization.ipynb\u001b[0m*\r\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,zipfile\n",
    "dir_name = \"/data1/call_miner/Vinyas_Call_miner/call_miner\"\n",
    "os.chdir(dir_name)\n",
    "zip_ref = zipfile.ZipFile('Vail_CDR_Transcripts_Jun18.zip') # create zipfile object\n",
    "zip_ref.extractall('/data1/call_miner/Vinyas_Call_miner/call_miner/June_unzip') # extract file to dir\n",
    "        #zip_ref.close() # close file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract nested zipped files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,zipfile\n",
    "dir_name = '/data1/call_miner/Vinyas_Call_miner/call_miner/June_unzip'\n",
    "extension = \".zip\"\n",
    "\n",
    "os.chdir(dir_name) # change directory from working dir to dir with files\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through items in dir\n",
    "    if item.endswith(extension): # check for \".zip\" extension\n",
    "        file_name = os.path.abspath(item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        zip_ref.extractall('/data1/call_miner/Vinyas_Call_miner/call_miner/June_xml') #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply fix to xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml_unzipped\")\n",
    "import os, fnmatch\n",
    "def findReplace(directory, find, replace, filePattern):\n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        for filename in fnmatch.filter(files, filePattern):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()\n",
    "            s = s.replace(find, replace)\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)\n",
    "\n",
    "findReplace(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Dec_xml\", \"</segment>\\n<transcript>\", \"</segment>\\n</transcript>\", \"*.xml\")                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file '14326572.xml', mode 'r' at 0x7f9e584f3e40>\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_xml_unzipped\")\n",
    "d=open('14326572.xml')\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fix 01 : - Replace - \"</segment>\" --> \"</segment>\\n</transcript>\"\n",
    "\n",
    "#os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml_unzipped\")\n",
    "import os, fnmatch\n",
    "def findReplace(directory, find, replace, filePattern):\n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        for filename in fnmatch.filter(files, filePattern):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()\n",
    "            s = s.replace(find, replace)\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)\n",
    "\n",
    "findReplace(\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_xml_unzipped\", \"</segment>\", \"</segment>\\n</transcript>\", \"*.xml\")                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fix 02 : correct double replacemnts\n",
    "\n",
    "#os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml_unzipped\")\n",
    "import os, fnmatch\n",
    "def findReplace(directory, find, replace, filePattern):\n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        for filename in fnmatch.filter(files, filePattern):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()\n",
    "            s = s.replace(find, replace)\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)\n",
    "\n",
    "findReplace(\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_xml_unzipped\", \"</segment>\\n</transcript>\\n</transcript>\", \"</segment>\\n</transcript>\", \"*.xml\")                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 87, column 23",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m not well-formed (invalid token): line 87, column 23\n"
     ]
    }
   ],
   "source": [
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_xml_unzipped\")\n",
    "for filename in glob.glob('14326572.xml'):\n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1'))   \n",
    "                 root=tree.getroot()\n",
    "                 eureka_id=root.find('eureka_id').text\n",
    "                 with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_Text_data/\"+eureka_id+\".txt\",\"w\") as f:\n",
    "                        csvwriter = csv.writer(f)\n",
    "                        for time in root.findall('segment'):\n",
    "                            row=[]\n",
    "                            task_name = time.find('words').text\n",
    "                            row.append(task_name)\n",
    "                            csvwriter.writerow(row)\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract selected Eureka Id from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " yes\n"
     ]
    }
   ],
   "source": [
    "b=[u'13882341.xml']\n",
    "if  b in data_list:\n",
    "        print \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading selected ID's completed..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-24b14aa78384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#print \"file name is\",filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print\"Match Found\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXMLParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Extract both Customer and Agent channel data\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Apr_xml_unzipped\")\n",
    "# Open the csv file which has the list of call/eureka ids i.e. filenames that we wish to read and process\n",
    "with open (\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_Eureka_Id.csv\") as f2:\n",
    "    reader=csv.reader(f2)\n",
    "    data_list=list(reader)\n",
    "    \n",
    "#csvwriter = csv.writer(f1)\n",
    "print \"Reading selected ID's completed..\"\n",
    "for filename in glob.glob('*.xml'):\n",
    "    #print \"file name is\",filename\n",
    "    if filename in data_list:\n",
    "        #print\"Match Found\"\n",
    "        tree = ET.parse(filename,ET.XMLParser(encoding='Latin1')) \n",
    "        root=tree.getroot()\n",
    "        eureka_id=root.find('eureka_id').text\n",
    "        with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_selected_text_data/\"+eureka_id+\".txt\",\"w\") as f:\n",
    "            csvwriter = csv.writer(f)\n",
    "            for time in root.findall('segment'):\n",
    "                row=[]\n",
    "                task_name = time.find('words').text\n",
    "                row.append(task_name)\n",
    "                csvwriter.writerow(row)\n",
    "                           # print 'parsed...', filename\n",
    "\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodecsv as csv\n",
    "import glob, os\n",
    "import io\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Jul_text_data\")\n",
    "filepath=''\n",
    "# Open the csv file which has the list of call/eureka ids i.e. filenames that we wish to read and process\n",
    "with open (\"/data1/call_miner/Vinyas_Call_miner/call_miner/July_id.csv\") as f2:\n",
    "    reader=csv.reader(f2)\n",
    "    data_list=list(reader)\n",
    "f2.close()    \n",
    "\n",
    "data = [y for x in data_list for y in x]\n",
    "[x.encode('UTF8') for x in data]\n",
    "\n",
    "s = set(data)\n",
    "\n",
    "for filename in glob.glob('*.txt'):\n",
    "    if filename in s:\n",
    "        shutil.copy(filename,\"/data1/call_miner/Vinyas_Call_miner/call_miner/Paypal_Analysis/Jul_paypal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading selected ID's completed..\n"
     ]
    }
   ],
   "source": [
    "#Extract both Customer and Agent channel data\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/mar_xml\")\n",
    "# Open the csv file which has the list of call/eureka ids i.e. filenames that we wish to read and process\n",
    "with open (\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_Eureka_Id.csv\") as f2:\n",
    "    reader=csv.reader(f2)\n",
    "    data_list=list(reader)\n",
    "    \n",
    "#csvwriter = csv.writer(f1)\n",
    "print \"Reading selected ID's completed..\"\n",
    "for i in data_list:\n",
    "    for filename in glob.glob('*.xml'):\n",
    "        #print \"i value is\",i\n",
    "        #print \"file name is\",filename\n",
    "        if filename in i:\n",
    "            #print\"Match Found\"\n",
    "            tree = ET.parse(filename,ET.XMLParser(encoding='Latin1')) \n",
    "            root=tree.getroot()\n",
    "            eureka_id=root.find('eureka_id').text\n",
    "            with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Mar_text_data/\"+eureka_id+\".txt\",\"w\") as f:\n",
    "                csvwriter = csv.writer(f)\n",
    "                for time in root.findall('segment'):\n",
    "                    row=[]\n",
    "                    task_name = time.find('words').text\n",
    "                    row.append(task_name)\n",
    "                    csvwriter.writerow(row)\n",
    "                           # print 'parsed...', filename\n",
    "\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract  call duration,wc and silence\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import time\n",
    "\n",
    "#from __future__ import print_function\n",
    "#log = open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/mar_output.txt\", \"w\")\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/June_xml\")\n",
    "eureka_id=[]\n",
    "duration=[]\n",
    "silence=[]\n",
    "wc=[]\n",
    "\n",
    "for filename in glob.glob('15140591.xml'):\n",
    "                 #print (\"parsing file\",filename)   \n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1')) \n",
    "                 root=tree.getroot()\n",
    "                 eureka_id.append(root.find('eureka_id').text)\n",
    "                 #print root.find('wav_length_sec').text   \n",
    "                 duration.append (time.strftime(\"%H.%M.%S\", time.gmtime(int(root.find('wav_length_sec').text))))\n",
    "                 silence.append(time.strftime(\"%H.%M.%S\", time.gmtime((int(root.find('total_silence_sec').text)))))\n",
    "                 #print root.find('total_silence_sec').text\n",
    "                 wc.append(root.find('word_count').text)\n",
    "\n",
    "data={'eureka_id':eureka_id,'call_duration':duration,'silence':silence,'word_count':wc}                 \n",
    "                 \n",
    "measure_df=pd.DataFrame(data)  \n",
    "\n",
    "#measure_df.to_csv(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/June/June_400I_10P/June_call_measures.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract  call duration,wc and silence\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import time\n",
    "\n",
    "#from __future__ import print_function\n",
    "#log = open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/mar_output.txt\", \"w\")\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/June_xml\")\n",
    "eureka_id=[]\n",
    "duration=[]\n",
    "silence=[]\n",
    "wc=[]\n",
    "\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 #print (\"parsing file\",filename)   \n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1')) \n",
    "                 root=tree.getroot()\n",
    "                 eureka_id.append(root.find('eureka_id').text)\n",
    "                 #print root.find('wav_length_sec').text   \n",
    "                 duration.append (int(root.find('wav_length_sec').text))\n",
    "                 silence.append (int(root.find('total_silence_sec').text))\n",
    "                 #print root.find('total_silence_sec').text\n",
    "                 wc.append(int(root.find('word_count').text))\n",
    "\n",
    "data={'eureka_id':eureka_id,'call_duration':duration,'silence':silence,'word_count':wc}                 \n",
    "                 \n",
    "measure_df=pd.DataFrame(data)  \n",
    "\n",
    "measure_df.to_csv(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/June/June_400I_10P/June_call_measures_V02.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Call Duration and speaker volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import time\n",
    "\n",
    "#from __future__ import print_function\n",
    "#log = open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/mar_output.txt\", \"w\")\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/June_xml\")\n",
    "eureka_id=[]\n",
    "duration=[]\n",
    "silence=[]\n",
    "wc=[]\n",
    "cust=[]\n",
    "agent=[]\n",
    "\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 #print (\"parsing file\",filename)   \n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1')) \n",
    "                 root=tree.getroot()\n",
    "                 eureka_id.append(root.find('eureka_id').text)\n",
    "                 #print root.find('wav_length_sec').text   \n",
    "                 duration.append (int(root.find('wav_length_sec').text))\n",
    "                 silence.append (int(root.find('total_silence_sec').text))\n",
    "                 #print root.find('total_silence_sec').text\n",
    "                 wc.append(int(root.find('word_count').text))\n",
    "                 c=0\n",
    "                 a=0\n",
    "                 for time in root.findall('segment'):\n",
    "                            if time.find('speaker').text=='Customer':                        \n",
    "                                c=c+1\n",
    "                                #print(c)\n",
    "                            else: a=a+1\n",
    "                 #print(a,c)             \n",
    "                 cust.append(c) \n",
    "                 agent.append(a)\n",
    "                                            \n",
    "                            \n",
    "                                \n",
    "\n",
    "data={'Eureka_id':eureka_id,'Call_duration':duration,'silence':silence,'word_count':wc,'cust':cust,'agent':agent}                 \n",
    "                 \n",
    "df_facts=pd.DataFrame(data)                   \n",
    "\n",
    "df_facts.to_csv(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/June/June_400I_10P/Jun_call_spr_cnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mdf=pd.read_csv(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/June/June_400I_10P/June_call_measures_V02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call_duration     int64\n",
       "Eureka_id        object\n",
       "agent             int64\n",
       "cust              int64\n",
       "silence           int64\n",
       "word_count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_facts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056069, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11:43'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.strftime(\"%M:%S\", time.gmtime(703))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call_duration</th>\n",
       "      <th>Eureka_id</th>\n",
       "      <th>agent</th>\n",
       "      <th>cust</th>\n",
       "      <th>silence</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>15342212</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>57</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>443</td>\n",
       "      <td>15334500</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>140</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164</td>\n",
       "      <td>15361784</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>746</td>\n",
       "      <td>15354039</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>360</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439</td>\n",
       "      <td>15325210</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>77</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Call_duration Eureka_id  agent  cust  silence  word_count\n",
       "0            148  15342212     14    13       57         304\n",
       "1            443  15334500     47    48      140        1035\n",
       "2            164  15361784     36    35       25         496\n",
       "3            746  15354039     65    64      360        1278\n",
       "4            439  15325210     34    34       77        1074"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_facts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "x=measure_df['call_duration'].astype(float)<1.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <type 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-a3d43bb61894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeasure_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasure_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'call_duration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%M:%S\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data1/ANACONDA/Anaconda2.7/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         raise TypeError(\"cannot convert the series to \"\n\u001b[0;32m---> 93\u001b[0;31m                         \"{0}\".format(str(converter)))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot convert the series to <type 'int'>"
     ]
    }
   ],
   "source": [
    "measure_df['cd']=int(measure_df['call_duration']).apply(time.strftime(\"%M:%S\", time.gmtime()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "call_duration     object\n",
       "eureka_id         object\n",
       "silence           object\n",
       "word_count        object\n",
       "cd               float64\n",
       "sil              float64\n",
       "wc                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "call_dur_1_30 = measure_df[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74135, 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_dur_1_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandasql as pdsql\n",
    "pysql = lambda q: pdsql.sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qry1 =\"select agent-cust as diff from df_facts where diff >=4 ;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=pysql(qry1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53369, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diff\n",
       "0    -1\n",
       "1    -1\n",
       "2    -1\n",
       "3    -1\n",
       "4    -1\n",
       "5    -1\n",
       "6    -1\n",
       "7    -1\n",
       "8    -1\n",
       "9    -1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract both Customer and Agent channel data\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "\n",
    "#from __future__ import print_function\n",
    "#log = open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/mar_output.txt\", \"w\")\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Jul_xml\")\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 #print \"parsing file\",filename   \n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1')) \n",
    "                 root=tree.getroot()\n",
    "                 eureka_id=root.find('eureka_id').text\n",
    "                 with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Jul_text_data/\"+eureka_id+\".txt\",\"w\") as f:\n",
    "                        csvwriter = csv.writer(f)\n",
    "                        for time in root.findall('segment'):\n",
    "                            row=[]\n",
    "                            task_name = time.find('words').text\n",
    "                            row.append(task_name)\n",
    "                            csvwriter.writerow(row)\n",
    "                 #print 'parsed...', filename\n",
    "\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 87, column 23",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m not well-formed (invalid token): line 87, column 23\n"
     ]
    }
   ],
   "source": [
    "#Extract only Customer channel data\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Dec_xml_unzip\")\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1'))\n",
    "                 root=tree.getroot()\n",
    "                 eureka_id=root.find('eureka_id').text\n",
    "                 with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_Cust_words/file_\"+eureka_id+\".txt\",\"w\") as f:\n",
    "                        csvwriter = csv.writer(f)\n",
    "                        for time in root.findall('segment'):\n",
    "                            row=[]\n",
    "                            if time.find('speaker').text=='Customer':\n",
    "                                task_name = time.find('words').text\n",
    "                                row.append(task_name)\n",
    "                                csvwriter.writerow(row)\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract only Agent channel data\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml_unzipped\")\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1'))\n",
    "                 root=tree.getroot()\n",
    "                 eureka_id=root.find('eureka_id').text\n",
    "                 with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_Cust_words/file_\"+eureka_id+\".txt\",\"w\") as f:\n",
    "                        csvwriter = csv.writer(f)\n",
    "                        for time in root.findall('segment'):\n",
    "                            row=[]\n",
    "                            if time.find('speaker').text=='Agent':\n",
    "                                task_name = time.find('words').text\n",
    "                                row.append(task_name)\n",
    "                                csvwriter.writerow(row)\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/ANACONDA/Anaconda2.7/lib/python2.7/site-packages/numpy/lib/utils.py:99: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  warnings.warn(depdoc, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim as gensimvis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen,PIPE\n",
    "\n",
    "cat = Popen([\"hadoop\", \"fs\", \"-cat\", \"/hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Nov17.zip\"], stdout=PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x7f1961c87f90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running system command: hdfs dfs -ls hdfs_file_path\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    " \n",
    " \n",
    "def run_cmd(args_list):\n",
    "    print('Running system command: {0}'.format(' '.join(args_list)))\n",
    "    proc = subprocess.Popen(args_list, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    s_output, s_err = proc.communicate()\n",
    "    s_return = proc.returncode\n",
    "    return s_return, s_output, s_err\n",
    "(ret, out, err)= run_cmd(['hdfs', 'dfs', '-ls', 'hdfs_file_path'])\n",
    "lines = out.split('\\n')\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running system command: hdfs dfs -get /data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/June/data_words_trigrams.csv /hpoc/edl/data/common/operations/callminer_data/call_miner/Lavanya\n"
     ]
    }
   ],
   "source": [
    "#Run Hadoop get command in Python\n",
    "(ret, out, err)= run_cmd(['hdfs', 'dfs', '-get', '/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/June/data_words_trigrams.csv', '/hpoc/edl/data/common/operations/callminer_data/call_miner/Lavanya'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running system command: hdfs dfs -get /hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Jun18.zip /data1/call_miner/Vinyas_Call_miner/call_miner\n"
     ]
    }
   ],
   "source": [
    "#Run Hadoop put command in Python\n",
    "(ret, out, err)= run_cmd(['hdfs', 'dfs', '-get', '/hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Jun18.zip', '/data1/call_miner/Vinyas_Call_miner/call_miner'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,zipfile\n",
    "#dir_name = \"hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/\"\n",
    "#os.chdir(dir_name)\n",
    "#zip_ref = zipfile.ZipFile(cat) # create zipfile object\n",
    "#zip_ref.extractall('hdfs:/hpoc/edl/data/common/operations/callminer_data/call_miner/Lavanya/nov_unzipped') # extract file to dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_Walmart\")\n",
    "path='/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_walmart_data.txt'\n",
    "filenames = glob.glob('*.txt') \n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for file in filenames:\n",
    "        with open(file) as infile:\n",
    "            f.write(infile.read()+'\\n')           \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'okay no problem then my pleasure trip ticket to thank you for calling and for being a valued score words customer you have a great day now bye bye \\r\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "RootDir1 = \"/data1/call_miner/Vinyas_Call_miner/call_miner/Apr_xml\"\n",
    "TargetFolder = \"/data1/call_miner/Vinyas_Call_miner/call_miner/Apr_xml_unzip\"\n",
    "for root, dirs, files in os.walk((os.path.normpath(RootDir1)), topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith('.xml'):\n",
    "                #print \"Found\"\n",
    "                SourceFolder = os.path.join(root,name)\n",
    "                shutil.copy2(SourceFolder, TargetFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner\")\n",
    "path='/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_Dec_9_decile.txt'\n",
    "filenames = ['Dec_9_decile_merged.txt','Feb_9_decile_merged.txt'] \n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for file in filenames:\n",
    "        with open(file) as infile:\n",
    "            f.write(infile.read()+'\\n')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
