{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Different ways of reading and parsing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.1 s, sys: 4.89 s, total: 11 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "import os,zipfile\n",
    "dir_name = \"/data1/call_miner/Vinyas_Call_miner/call_miner\"\n",
    "os.chdir(dir_name)\n",
    "zip_ref = zipfile.ZipFile('Vail_CDR_Transcripts_Jan18.zip') # create zipfile object\n",
    "%time zip_ref.extractall('/data1/call_miner/Vinyas_Call_miner/call_miner/Jan_unzip') # extract file to dir\n",
    "        #zip_ref.close() # close file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract nested zipped files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,zipfile\n",
    "dir_name = '/data1/call_miner/Vinyas_Call_miner/call_miner/Jan_unzip'\n",
    "extension = \".zip\"\n",
    "\n",
    "os.chdir(dir_name) # change directory from working dir to dir with files\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through items in dir\n",
    "    if item.endswith(extension): # check for \".zip\" extension\n",
    "        file_name = os.path.abspath(item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        zip_ref.extractall('/data1/call_miner/Vinyas_Call_miner/call_miner/Jan_xml') #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply fix to xml - use this to fix the parsing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml_unzipped\")\n",
    "import os, fnmatch\n",
    "def findReplace(directory, find, replace, filePattern):\n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        for filename in fnmatch.filter(files, filePattern):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()\n",
    "            s = s.replace(find, replace)\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)\n",
    "\n",
    "findReplace(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml\", \"</segment>\\n<transcript>\", \"</segment>\\n</transcript>\", \"*.xml\")                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fix 01 : - Replace - \"</segment>\" --> \"</segment>\\n</transcript>\"\n",
    "\n",
    "#os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml_unzipped\")\n",
    "import os, fnmatch\n",
    "def findReplace(directory, find, replace, filePattern):\n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        for filename in fnmatch.filter(files, filePattern):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()\n",
    "            s = s.replace(find, replace)\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)\n",
    "\n",
    "findReplace(\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_xml_unzipped\", \"</segment>\", \"</segment>\\n</transcript>\", \"*.xml\")                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fix 02 : correct double replacemnts\n",
    "\n",
    "#os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml_unzipped\")\n",
    "import os, fnmatch\n",
    "def findReplace(directory, find, replace, filePattern):\n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        for filename in fnmatch.filter(files, filePattern):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()\n",
    "            s = s.replace(find, replace)\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)\n",
    "\n",
    "findReplace(\"/data1/call_miner/Vinyas_Call_miner/call_miner/May_xml_unzipped\", \"</segment>\\n</transcript>\\n</transcript>\", \"</segment>\\n</transcript>\", \"*.xml\")                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Text from XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract both Customer and Agent channel data\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "import sys\n",
    "\n",
    "#from __future__ import print_function\n",
    "#log = open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/mar_output.txt\", \"w\")\n",
    "#sys.stdout = log  -- saves print output to a log file ,uncomment to track error file \n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Sep_xml\")\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 #print (\"parsing file\",filename)  -- uncomment to track error file \n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1')) \n",
    "                 root=tree.getroot()\n",
    "                 eureka_id=root.find('eureka_id').text\n",
    "                 with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Sep_text_data/\"+eureka_id+\".txt\",\"w\") as f:\n",
    "                        csvwriter = csv.writer(f)\n",
    "                        for time in root.findall('segment'):\n",
    "                            row=[]\n",
    "                            task_name = time.find('words').text\n",
    "                            row.append(task_name)\n",
    "                            csvwriter.writerow(row)\n",
    "                # print ('parsed...', filename) -- uncomment to track error file\n",
    "\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Specific files - Exclude/Include files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodecsv as csv\n",
    "import glob, os\n",
    "import io\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Sep_text_data\")\n",
    "filepath=''\n",
    "# Open the csv file which has the list of call/eureka ids i.e. filenames that we wish to read and process\n",
    "with open (\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/September/Sep_no_noise/sep_noise_id.csv\") as f2:\n",
    "    reader=csv.reader(f2)\n",
    "    data_list=list(reader)\n",
    "f2.close()    \n",
    "\n",
    "data = [y for x in data_list for y in x]\n",
    "[x.encode('UTF8') for x in data]\n",
    "\n",
    "s = set(data)\n",
    "\n",
    "for filename in glob.glob('*.txt'):\n",
    "    if filename not in s:\n",
    "        shutil.copy(filename,\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/September/Sep_denoise_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Call Duration and speaker volume - this derived dataset helps in identifying noise calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import time\n",
    "\n",
    "#from __future__ import print_function\n",
    "#log = open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/mar_output.txt\", \"w\")\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Sep_xml\")\n",
    "eureka_id=[]\n",
    "duration=[]\n",
    "silence=[]\n",
    "wc=[]\n",
    "cust=[]\n",
    "agent=[]\n",
    "\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 #print (\"parsing file\",filename)   \n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1')) \n",
    "                 root=tree.getroot()\n",
    "                 eureka_id.append(root.find('eureka_id').text)\n",
    "                 #print root.find('wav_length_sec').text   \n",
    "                 duration.append (int(root.find('wav_length_sec').text))\n",
    "                 silence.append (int(root.find('total_silence_sec').text))\n",
    "                 #print root.find('total_silence_sec').text\n",
    "                 wc.append(int(root.find('word_count').text))\n",
    "                 c=0 # initialize the counter\n",
    "                 a=0\n",
    "                 for time in root.findall('segment'):\n",
    "                            if time.find('speaker').text=='Customer':                        \n",
    "                                c=c+1\n",
    "                                #print(c)\n",
    "                            else: a=a+1\n",
    "                 #print(a,c)             \n",
    "                 cust.append(c) \n",
    "                 agent.append(a)\n",
    "                                            \n",
    "                            \n",
    "                                \n",
    "\n",
    "data={'Eureka_id':eureka_id,'Call_duration':duration,'silence':silence,'word_count':wc,'cust':cust,'agent':agent}                 \n",
    "                 \n",
    "df_facts=pd.DataFrame(data)                   \n",
    "\n",
    "df_facts.to_csv(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/September/Sep_no_noise/Sep_call_spr_cnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_facts=pd.read_csv(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/September/Sep_no_noise/Sep_call_spr_cnt.csv\")\n",
    "\n",
    "#df_facts=pd.read_csv(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/April/Noise_calls_Apr/Apr_call_spr_cnt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       int64\n",
       "Call_duration    int64\n",
       "Eureka_id        int64\n",
       "agent            int64\n",
       "cust             int64\n",
       "silence          int64\n",
       "word_count       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_facts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(871657, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_facts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call_duration</th>\n",
       "      <th>Eureka_id</th>\n",
       "      <th>agent</th>\n",
       "      <th>cust</th>\n",
       "      <th>silence</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>16862366</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>16862374</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>274</td>\n",
       "      <td>16862376</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>109</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>16862372</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277</td>\n",
       "      <td>16862382</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>101</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Call_duration Eureka_id  agent  cust  silence  word_count\n",
       "0            115  16862366      8     8       41         238\n",
       "1            105  16862374     16    17       25         286\n",
       "2            274  16862376     26    26      109         572\n",
       "3            155  16862372     10     9       78         256\n",
       "4            277  16862382     32    31      101         615"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_facts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check various noise calls based on conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandasql as pdsql\n",
    "pysql = lambda q: pdsql.sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qry1 =\"select * from df_facts where cust>3 and agent>3 and word_count<=150 and silence >=200;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=pysql(qry1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape # gets rows,columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.to_csv('/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/September/Sep_no_noise/c_a_sil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Call_duration</th>\n",
       "      <th>Eureka_id</th>\n",
       "      <th>agent</th>\n",
       "      <th>cust</th>\n",
       "      <th>silence</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352</td>\n",
       "      <td>109</td>\n",
       "      <td>15362340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>471</td>\n",
       "      <td>126</td>\n",
       "      <td>15359057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567</td>\n",
       "      <td>33</td>\n",
       "      <td>15360494</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>649</td>\n",
       "      <td>80</td>\n",
       "      <td>15324031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704</td>\n",
       "      <td>83</td>\n",
       "      <td>15351018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>714</td>\n",
       "      <td>74</td>\n",
       "      <td>15323320</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1183</td>\n",
       "      <td>29</td>\n",
       "      <td>15358068</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1381</td>\n",
       "      <td>68</td>\n",
       "      <td>15355402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1466</td>\n",
       "      <td>67</td>\n",
       "      <td>15349229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1516</td>\n",
       "      <td>54</td>\n",
       "      <td>15332066</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Call_duration  Eureka_id  agent  cust  silence  word_count\n",
       "0         352            109   15362340      1     0       79         100\n",
       "1         471            126   15359057      1     0       95          91\n",
       "2         567             33   15360494      1     0       13          74\n",
       "3         649             80   15324031      1     0       44         119\n",
       "4         704             83   15351018      1     0       37         169\n",
       "5         714             74   15323320      1     0       34         124\n",
       "6        1183             29   15358068      1     0        7          64\n",
       "7        1381             68   15355402      1     0       29         142\n",
       "8        1466             67   15349229      1     0       48          45\n",
       "9        1516             54   15332066      1     0       49          16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Customer or Agent channel text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract only Customer channel data\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Oct_xml\")\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1'))\n",
    "                 root=tree.getroot()\n",
    "                 eureka_id=root.find('eureka_id').text\n",
    "                 with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Lavanya/Sentiment_Model/Oct_cust_text/\"+eureka_id+\".txt\",\"w\") as f:\n",
    "                        csvwriter = csv.writer(f)\n",
    "                        for time in root.findall('segment'):\n",
    "                            row=[]\n",
    "                            if time.find('speaker').text=='Customer':\n",
    "                                task_name = time.find('words').text\n",
    "                                row.append(task_name)\n",
    "                                csvwriter.writerow(row)\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract only Agent channel data\n",
    "\n",
    "import unicodecsv as csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import io\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_xml_unzipped\")\n",
    "for filename in glob.glob('*.xml'):\n",
    "                 tree = ET.parse(filename,ET.XMLParser(encoding='Latin1'))\n",
    "                 root=tree.getroot()\n",
    "                 eureka_id=root.find('eureka_id').text\n",
    "                 with open(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_Cust_words/file_\"+eureka_id+\".txt\",\"w\") as f:\n",
    "                        csvwriter = csv.writer(f)\n",
    "                        for time in root.findall('segment'):\n",
    "                            row=[]\n",
    "                            if time.find('speaker').text=='Agent':\n",
    "                                task_name = time.find('words').text\n",
    "                                row.append(task_name)\n",
    "                                csvwriter.writerow(row)\n",
    "                            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Read & Write data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running system command: hdfs dfs -ls hdfs_file_path\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    " \n",
    " \n",
    "def run_cmd(args_list):\n",
    "    print('Running system command: {0}'.format(' '.join(args_list)))\n",
    "    proc = subprocess.Popen(args_list, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    s_output, s_err = proc.communicate()\n",
    "    s_return = proc.returncode\n",
    "    return s_return, s_output, s_err\n",
    "(ret, out, err)= run_cmd(['hdfs', 'dfs', '-ls', 'hdfs_file_path'])\n",
    "lines = out.split('\\n')\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running system command: hdfs dfs -put /data1/call_miner/Vinyas_Call_miner/call_miner/syf_Vail_CDR_Transcripts_Sep18.zip /hpoc/edl/data/common/operations/callminer_data/call_miner\n"
     ]
    }
   ],
   "source": [
    "#Run Hadoop put command in Python\n",
    "(ret, out, err)= run_cmd(['hdfs', 'dfs', '-put', '/data1/call_miner/Vinyas_Call_miner/call_miner/syf_Vail_CDR_Transcripts_Sep18.zip', '/hpoc/edl/data/common/operations/callminer_data/call_miner'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running system command: hdfs dfs -get /hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Jan18.zip /data1/call_miner/Vinyas_Call_miner/call_miner\n"
     ]
    }
   ],
   "source": [
    "#Run Hadoop get command in Python\n",
    "(ret, out, err)= run_cmd(['hdfs', 'dfs', '-get', '/hpoc/edl/data/common/operations/callminer_data/call_miner/Vail_CDR_Transcripts_Jan18.zip', '/data1/call_miner/Vinyas_Call_miner/call_miner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other data format - Merge multiple text files in an folder to single text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_Walmart\")\n",
    "path='/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_walmart_data.txt'\n",
    "filenames = glob.glob('*.txt') \n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for file in filenames:\n",
    "        with open(file) as infile:\n",
    "            f.write(infile.read()+'\\n')           \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use for this Data Format - Vail_CDR_Transcripts_Apr18_Corrected -> syf_2018_04_01.zip-> syf_2018_04_01->15759300.xml\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "RootDir1 = \"/data1/call_miner/Vinyas_Call_miner/call_miner/Apr_xml\"\n",
    "TargetFolder = \"/data1/call_miner/Vinyas_Call_miner/call_miner/Apr_xml_unzip\"\n",
    "for root, dirs, files in os.walk((os.path.normpath(RootDir1)), topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith('.xml'):\n",
    "                #print \"Found\"\n",
    "                SourceFolder = os.path.join(root,name)\n",
    "                shutil.copy2(SourceFolder, TargetFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "# Set the working directory\n",
    "os.chdir(\"/data1/call_miner/Vinyas_Call_miner/call_miner\")\n",
    "path='/data1/call_miner/Vinyas_Call_miner/call_miner/Feb_Dec_9_decile.txt'\n",
    "filenames = ['Dec_9_decile_merged.txt','Feb_9_decile_merged.txt'] \n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for file in filenames:\n",
    "        with open(file) as infile:\n",
    "            f.write(infile.read()+'\\n')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
